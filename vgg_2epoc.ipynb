{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0d6eed-1720-4c8b-81ec-30a13b22aff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f322f16c-7462-43a2-8c65-a54e014afd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "#os.chdir('archive/asl_alphabet_train/asl_alphabet_train')\n",
    "os.listdir()\n",
    "train_dir = '../jagannathan/ASL_DATA_4K/archive/asl_alphabet_train/asl_alphabet_train/'\n",
    "test_dir = '../jagannathan/ASL_DATA_4K/archive/asl_alphabet_test/asl_alphabet_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0fc3e59-570b-4321-8c2f-8572f0114297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 05:02:42.264255: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199995000 Hz\n",
      "2021-11-19 05:02:42.266222: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e71d9e3680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-19 05:02:42.266246: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-19 05:02:42.268314: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "# Init the VGG model \n",
    "vgg_conv = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a1266a-3187-4e79-b29b-d18feeefdee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f97dc659710> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97dc62f4d0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97dc413350> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f97dbb77610> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97dbb92b90> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97dc413190> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f97d80d6e90> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97d80dc510> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97d80e0990> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97d80e5a10> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f97dc413f90> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97d8070bd0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97d807a590> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97d807d2d0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f97d8083d10> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97d8087950> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97d8091250> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f97d8095c10> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f97d809aa10> False\n"
     ]
    }
   ],
   "source": [
    "# Freeze all the layers\n",
    "for layer in vgg_conv.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba238fe0-449c-4d66-b0f7-b2e6d8393893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 29)                29725     \n",
      "=================================================================\n",
      "Total params: 16,842,589\n",
      "Trainable params: 2,127,901\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the vgg convolutional base model\n",
    "model.add(vgg_conv)\n",
    "\n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(29, activation='softmax'))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff14c0f-4c30-42e9-a16b-4935e500bbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87000 images belonging to 29 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the normalized images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 100\n",
    "val_batchsize = 10\n",
    "\n",
    "# Data generator for training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Data generator for validation data\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24e7355-9564-4e5a-a0b6-33948695e7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 29)                29725     \n",
      "=================================================================\n",
      "Total params: 16,842,589\n",
      "Trainable params: 2,127,901\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b9ee6a-2c82-4c2f-8e3e-14d3478bc073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "870/870 [==============================] - 1539s 2s/step - loss: 1.3895 - acc: 0.6558\n",
      "Epoch 2/2\n",
      "870/870 [==============================] - 1075s 1s/step - loss: 0.4487 - acc: 0.8939\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "# Configure the model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=\n",
    "         train_generator.samples/train_generator.batch_size,\n",
    "      epochs=2,\n",
    "      validation_data=validation_generator, \n",
    "      validation_steps=\n",
    "         validation_generator.samples/validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98dbf4f3-71d9-49b5-8686-b289c23ebcfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12743/2618147090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Run the function to illustrate accuracy and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mvisualize_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_12743/2618147090.py\u001b[0m in \u001b[0;36mvisualize_results\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Plot the accuracy and loss curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "# Utility function for plotting of the model results\n",
    "def visualize_results(history):\n",
    "    # Plot the accuracy and loss curves\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run the function to illustrate accuracy and loss\n",
    "visualize_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b0c0694-dcdc-4092-a1e8-fd7b56c26320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3895189762115479, 0.44872114062309265],\n",
       " 'acc': [0.6557931303977966, 0.8939425349235535]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c373a0a-72c7-4b7c-852c-50bc7e05acab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m84"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
