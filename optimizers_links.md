* Important links for Optimizers:

- A Good Survey of Optimizers: 
https://ruder.io/optimizing-gradient-descent/

-RMSProp Optimizer - The RMSprop optimizer restricts the oscillations in the vertical direction. Therefore, we can increase our learning rate and our algorithm could take larger steps in the horizontal direction converging faster. The difference between RMSprop and gradient descent is on how the gradients are calculated. 

https://towardsdatascience.com/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b